{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Food-101 computer vision project\n",
        "###resnet50\n",
        "###Model Training (80%train/10%val/10%test/)\n"
      ],
      "metadata": {
        "id": "JHqkAJAhMnXX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hCocNc8gMgm5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "from torch.utils.data import Dataset, DataLoader, random_split # Import random_split\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "from IPython.display import Image as DisplayImage, display\n",
        "import gradio as gr\n",
        "\n",
        "# --- 0. Environment Setup and Data Download/Extraction ---\n",
        "print(\"--- 0. Environment Setup and Data Download/Extraction ---\")\n",
        "# Remember to run this line in Colab to mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "print(\"Google Drive mounted successfully.\" if os.path.exists('/content/drive/MyDrive') else \"Google Drive mounting failed.\")\n",
        "\n",
        "\n",
        "# Set Google Drive storage path\n",
        "drive_path = \"/content/drive/MyDrive/food101_project\"\n",
        "tar_path = f\"{drive_path}/food-101.tar.gz\"\n",
        "extract_path = \"/content\" # Colab's temporary space for faster extraction\n",
        "\n",
        "# Check and create the project folder on Google Drive\n",
        "os.makedirs(drive_path, exist_ok=True)\n",
        "\n",
        "# Check if Food-101 compressed file is downloaded, if not, download it\n",
        "if not os.path.exists(tar_path):\n",
        "    print(f\"Downloading Food-101 dataset to {drive_path}...\")\n",
        "    !wget http://data.vision.ee.ethz.ch/cvl/food-101.tar.gz -P {drive_path}\n",
        "    print(\"Food-101 dataset downloaded.\")\n",
        "else:\n",
        "    print(\"food-101.tar.gz already downloaded, skipping download.\")\n",
        "\n",
        "# Check if Food-101 folder is extracted, if not, extract it\n",
        "if not os.path.exists(os.path.join(extract_path, \"food-101\")):\n",
        "    print(f\"Extracting food-101.tar.gz to {extract_path}...\")\n",
        "    !tar -xzf {tar_path} -C {extract_path}\n",
        "    print(\"Extraction complete.\")\n",
        "else:\n",
        "    print(\"Food-101 folder already extracted, skipping extraction.\")\n",
        "\n",
        "# Confirm data availability\n",
        "if os.path.exists(\"/content/food-101/images\") and os.path.exists(\"/content/food-101/meta\"):\n",
        "    print(\"Food-101 dataset is ready.\")\n",
        "else:\n",
        "    print(\"Food-101 dataset preparation failed. Please check download and extraction steps.\")\n",
        "\n",
        "\n",
        "# --- 1. Define Food-101 Food Class Names ---\n",
        "print(\"\\n--- 1. Define Food-101 Food Class Names ---\")\n",
        "food101_classes = [\n",
        "    \"apple_pie\", \"baby_back_ribs\", \"baklava\", \"beef_carpaccio\", \"beef_tartare\",\n",
        "    \"beet_salad\", \"beignets\", \"bibimbap\", \"bread_pudding\", \"breakfast_burrito\",\n",
        "    \"bruschetta\", \"caesar_salad\", \"cannoli\", \"caprese_salad\", \"carrot_cake\",\n",
        "    \"ceviche\", \"cheesecake\", \"cheese_plate\", \"chicken_curry\", \"chicken_quesadilla\",\n",
        "    \"chicken_wings\", \"chocolate_cake\", \"chocolate_mousse\", \"churros\", \"clam_chowder\",\n",
        "    \"club_sandwich\", \"crab_cakes\", \"creme_brulee\", \"croque_madame\", \"cup_cakes\",\n",
        "    \"deviled_eggs\", \"donuts\", \"dumplings\", \"edamame\", \"eggs_benedict\",\n",
        "    \"escargots\", \"falafel\", \"filet_mignon\", \"fish_and_chips\", \"foie_gras\",\n",
        "    \"french_fries\", \"french_onion_soup\", \"french_toast\", \"fried_calamari\", \"fried_rice\",\n",
        "    \"frozen_yogurt\", \"garlic_bread\", \"gnocchi\", \"greek_salad\", \"grilled_cheese_sandwich\",\n",
        "    \"grilled_salmon\", \"guacamole\", \"gyoza\", \"hamburger\", \"hot_and_sour_soup\",\n",
        "    \"hot_dog\", \"huevos_rancheros\", \"hummus\", \"ice_cream\", \"lasagna\",\n",
        "    \"lobster_bisque\", \"lobster_roll_sandwich\", \"macaroni_and_cheese\", \"macarons\", \"miso_soup\",\n",
        "    \"mussels\", \"nachos\", \"omelette\", \"onion_rings\", \"oysters\",\n",
        "    \"pad_thai\", \"paella\", \"pancakes\", \"panna_cotta\", \"peking_duck\",\n",
        "    \"pho\", \"pizza\", \"pork_chop\", \"poutine\", \"prime_rib\",\n",
        "    \"pulled_pork_sandwich\", \"ramen\", \"ravioli\", \"red_velvet_cake\", \"risotto\",\n",
        "    \"samosa\", \"sashimi\", \"scallops\", \"seaweed_salad\", \"shrimp_and_grits\",\n",
        "    \"spaghetti_bolognese\", \"spaghetti_carbonara\", \"spring_rolls\", \"steak\", \"strawberry_shortcake\",\n",
        "    \"sushi\", \"tacos\", \"takoyaki\", \"tiramisu\", \"tuna_tartare\",\n",
        "    \"waffles\"\n",
        "]\n",
        "class_names = food101_classes # Point class_names to food101_classes\n",
        "\n",
        "\n",
        "# --- 2. Load Calorie Lookup Table ---\n",
        "print(\"\\n--- 2. Load Calorie Lookup Table ---\")\n",
        "\n",
        "# Your Excel file path\n",
        "calorie_excel_path = os.path.join(drive_path, \"calorie_lookup_table.xlsx\")\n",
        "\n",
        "# Initialize calorie_dict as an empty dictionary in case loading fails\n",
        "calorie_dict = {}\n",
        "\n",
        "if os.path.exists(calorie_excel_path):\n",
        "    print(f\"Loading calorie table from {calorie_excel_path}...\")\n",
        "    try:\n",
        "        # Load XLSX file using pd.read_excel\n",
        "        df_calories = pd.read_excel(calorie_excel_path)\n",
        "\n",
        "        # Confirm DataFrame contains 'food_category' and 'calories_per_serving' columns\n",
        "        if 'food_category' in df_calories.columns and 'calories_per_serving' in df_calories.columns:\n",
        "            # Convert DataFrame back to a dictionary for use in predict_image\n",
        "            # Use 'food_category' as key and 'calories_per_serving' as value\n",
        "            calorie_dict = pd.Series(df_calories['calories_per_serving'].values, index=df_calories['food_category']).to_dict()\n",
        "            print(\"Calorie table loaded successfully.\")\n",
        "        else:\n",
        "            print(f\"Excel file {calorie_excel_path} is missing 'food_category' or 'calories_per_serving' columns.\")\n",
        "            print(\"Please ensure your Excel file has the correct column names.\")\n",
        "            # If columns are incorrect, use a random calorie table\n",
        "            calorie_dict = {food: random.randint(150, 600) for food in food101_classes}\n",
        "            df_calories = pd.DataFrame(list(calorie_dict.items()), columns=['food', 'calories (kcal)'])\n",
        "            print(f\"Generated a random calorie table as a substitute.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading Excel file: {e}\")\n",
        "        print(\"Will create a random calorie table instead.\")\n",
        "        calorie_dict = {food: random.randint(150, 600) for food in food101_classes}\n",
        "        df_calories = pd.DataFrame(list(calorie_dict.items()), columns=['food', 'calories (kcal)'])\n",
        "        print(f\"Generated a random calorie table as a substitute.\")\n",
        "\n",
        "else:\n",
        "    print(f\"Calorie lookup table not found at {calorie_excel_path}.\")\n",
        "    print(\"Will create a random calorie table instead.\")\n",
        "    # Fallback: If file not found, create a random calorie dictionary\n",
        "    calorie_dict = {food: random.randint(150, 600) for food in food101_classes}\n",
        "    df_calories = pd.DataFrame(list(calorie_dict.items()), columns=['food', 'calories (kcal)'])\n",
        "    # Save this randomly generated calorie table to CSV for future use\n",
        "    df_calories.to_csv(os.path.join(drive_path, \"food101_random_calorie_table.csv\"), index=False)\n",
        "    print(f\"Generated and saved a random calorie table.\")\n",
        "\n",
        "\n",
        "# --- 3. Custom Food101 Dataset Class ---\n",
        "print(\"\\n--- 3. Custom Food101 Dataset Class ---\")\n",
        "class Food101Dataset(Dataset):\n",
        "    def __init__(self, image_paths_list, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.image_paths = image_paths_list # Use the directly passed list of image paths\n",
        "\n",
        "        # Use externally defined food101_classes to ensure consistency of class indices\n",
        "        self.classes = food101_classes\n",
        "        self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.classes)}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        label = self.class_to_idx[img_path.split('/')[0]] # Parse class from path (e.g., \"apple_pie/12345\" -> \"apple_pie\")\n",
        "        img_full_path = os.path.join(self.root_dir, img_path + \".jpg\")\n",
        "\n",
        "        image = Image.open(img_full_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "print(\"Food101Dataset class defined.\")\n",
        "\n",
        "\n",
        "# --- 4. Data Loader Setup (80% Train, 10% Validation, 10% Test) ---\n",
        "print(\"\\n--- 4. Data Loader Setup (80% Train, 10% Validation, 10% Test) ---\")\n",
        "# Set paths for Food-101 images and metadata\n",
        "image_root = \"/content/food-101/images\"\n",
        "meta_root = \"/content/food-101/meta\"\n",
        "\n",
        "# **Define image preprocessing steps (add stronger data augmentation for training set)**\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)), # Random crop and resize, simulate different sizes/positions\n",
        "    transforms.RandomHorizontalFlip(), # Random horizontal flip\n",
        "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1), # Random color jitter\n",
        "    transforms.ToTensor(),         # Convert PIL image to PyTorch Tensor\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # Normalize image\n",
        "])\n",
        "\n",
        "# **Define preprocessing steps for validation and test sets (only essential transformations)**\n",
        "val_test_transform = transforms.Compose([\n",
        "    transforms.Resize((256)), # Typically resize larger first, then center crop\n",
        "    transforms.CenterCrop((224, 224)), # Center crop to model input size\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "\n",
        "# Load all image paths (from train.txt and test.txt)\n",
        "all_image_paths = []\n",
        "with open(os.path.join(meta_root, \"train.txt\"), 'r') as f:\n",
        "    all_image_paths.extend(f.read().splitlines())\n",
        "with open(os.path.join(meta_root, \"test.txt\"), 'r') as f:\n",
        "    all_image_paths.extend(f.read().splitlines())\n",
        "\n",
        "# Create a full dataset instance containing all images (using a generic transform for now)\n",
        "# Different transforms will be applied after random_split\n",
        "full_food101_dataset = Food101Dataset(image_paths_list=all_image_paths,\n",
        "                                     root_dir=image_root, transform=None) # Temporarily set to None here\n",
        "\n",
        "# Split into training, validation, and test sets (80% train, 10% val, 10% test)\n",
        "total_size = len(full_food101_dataset)\n",
        "train_size = int(0.8 * total_size)\n",
        "val_size = int(0.1 * total_size)\n",
        "test_size = total_size - train_size - val_size # Ensure sum equals total_size\n",
        "\n",
        "# Set random seed to ensure reproducibility of splits\n",
        "g = torch.Generator().manual_seed(42)\n",
        "\n",
        "# random_split returns Subset objects\n",
        "train_subset_raw, val_subset_raw, test_subset_raw = random_split(\n",
        "    full_food101_dataset,\n",
        "    [train_size, val_size, test_size],\n",
        "    generator=g\n",
        ")\n",
        "\n",
        "# Since random_split returns Subsets, we need a wrapper to apply different transforms\n",
        "# This DatasetWithTransform class will use the indices provided by Subset to reload images from the original dataset and apply the specified transformation\n",
        "class DatasetWithTransform(Dataset):\n",
        "    def __init__(self, subset, transform=None):\n",
        "        self.subset = subset\n",
        "        self.transform = transform\n",
        "        # Inherit class_to_idx and classes from the original dataset\n",
        "        # subset.dataset points to full_food101_dataset before random_split\n",
        "        self.class_to_idx = subset.dataset.class_to_idx\n",
        "        self.classes = subset.dataset.classes\n",
        "        self.root_dir = subset.dataset.root_dir\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Get the original index in the full dataset via the subset's internal index\n",
        "        original_idx_in_full_dataset = self.subset.indices[idx]\n",
        "        img_path_relative = self.subset.dataset.image_paths[original_idx_in_full_dataset]\n",
        "        label = self.subset.dataset.class_to_idx[img_path_relative.split('/')[0]]\n",
        "        img_full_path = os.path.join(self.root_dir, img_path_relative + \".jpg\")\n",
        "\n",
        "        image = Image.open(img_full_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.subset)\n",
        "\n",
        "# Create new DatasetWithTransform instances for the split subsets, applying different transforms\n",
        "train_dataset = DatasetWithTransform(train_subset_raw, transform=train_transform)\n",
        "val_dataset = DatasetWithTransform(val_subset_raw, transform=val_test_transform)\n",
        "test_dataset = DatasetWithTransform(test_subset_raw, transform=val_test_transform)\n",
        "\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "print(f\"Total data loaded: {total_size} samples\")\n",
        "print(f\"Training data after split: {len(train_dataset)} samples (with enhanced data augmentation)\")\n",
        "print(f\"Validation data: {len(val_dataset)} samples (with standard preprocessing)\")\n",
        "print(f\"Test data: {len(test_dataset)} samples (with standard preprocessing)\")\n",
        "\n",
        "\n",
        "# --- 5. Model Initialization and Training (Including Checkpoint and GPU Usage Confirmation) ---\n",
        "print(\"\\n--- 5. Model Initialization and Training ---\")\n",
        "# Set training device (GPU preferred, otherwise CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device for training: {device}\")\n",
        "if device.type == 'cuda':\n",
        "    print(f\"CUDA is available! GPU Name: {torch.cuda.get_device_name(0)}\")\n",
        "    print(\"--- Initial GPU Status ---\")\n",
        "    !nvidia-smi # First check of GPU status\n",
        "    print(\"--------------------------\")\n",
        "else:\n",
        "    print(\"CUDA is NOT available. Training will use CPU. Please check your Colab runtime type (Runtime -> Change runtime type -> GPU).\")\n",
        "\n",
        "\n",
        "# Initialize ResNet model, using pre-trained weights\n",
        "# ----------------------------------------------------\n",
        "# **IMPORTANT: Choose your model here (uncomment the line you want to use)**\n",
        "\n",
        "# Use ResNet-18 (Accuracy was not good, started stagnating after 10th epoch)\n",
        "# model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
        "# model_name = \"food101_resnet18.pth\"\n",
        "\n",
        "# Or, use ResNet-50 (Higher accuracy, ultimately decided to use this model)\n",
        "model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
        "model_name = \"food101_resnet50.pth\" # Corresponding best model filename (without epoch and accuracy)\n",
        "# ----------------------------------------------------\n",
        "\n",
        "# Modify the final fully connected layer to match the 101 classes of Food-101\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, len(food101_classes))\n",
        "\n",
        "# Move the model to the specified device (GPU/CPU)\n",
        "model = model.to(device)\n",
        "\n",
        "# Define loss function (CrossEntropy for classification) and optimizer (Adam commonly used in deep learning)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001) # You can adjust the learning rate (lr)\n",
        "\n",
        "# Add learning rate scheduler\n",
        "# If validation loss doesn't decrease for 3 consecutive epochs, the learning rate will be reduced to 0.1 times its current value.\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
        "\n",
        "\n",
        "# Set model save path\n",
        "model_save_path = os.path.join(drive_path, model_name)\n",
        "\n",
        "# Check if a pre-trained model exists, load it if it does\n",
        "if os.path.exists(model_save_path):\n",
        "    try:\n",
        "        # Load the entire checkpoint including model, optimizer, and scheduler states\n",
        "        checkpoint = torch.load(model_save_path, map_location=device)\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        if 'scheduler_state_dict' in checkpoint:\n",
        "            scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
        "        # Also load best_val_accuracy and best_val_loss for continuation\n",
        "        best_val_accuracy = checkpoint.get('best_val_accuracy', 0.0)\n",
        "        best_val_loss = checkpoint.get('best_val_loss', float('inf'))\n",
        "        # Determine start_epoch for continuation\n",
        "        start_epoch = checkpoint.get('epoch', 0) + 1\n",
        "        print(f\"Pre-trained model state loaded from {model_save_path}. Resuming training from Epoch {start_epoch}.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading model {model_save_path}: {e}. Training model from scratch.\")\n",
        "        start_epoch = 0 # Start from scratch if loading fails\n",
        "        best_val_accuracy = 0.0 # Reset if starting from scratch\n",
        "        best_val_loss = float('inf') # Reset if starting from scratch\n",
        "else:\n",
        "    print(f\"Model file not found: {model_save_path}. Training model from scratch.\")\n",
        "    start_epoch = 0 # Start from scratch\n",
        "    best_val_accuracy = 0.0 # Reset if starting from scratch\n",
        "    best_val_loss = float('inf') # Reset if starting from scratch\n",
        "\n",
        "# Initialize best validation accuracy for saving the best model (if not loaded from checkpoint)\n",
        "# best_val_accuracy is now initialized directly from checkpoint or default 0.0\n",
        "\n",
        "# This variable will track the path of the best model file saved\n",
        "best_model_ever_saved_path = model_save_path # Initialize to the main save path\n",
        "\n",
        "\n",
        "# --- Model Training (Including Validation Process and More Detailed Saving Logic) ---\n",
        "print(f\"--- Starting Model Training (or Resuming Training) ---\")\n",
        "epochs_to_train_now = 15 # Number of epochs to train for now, you can adjust this\n",
        "\n",
        "for epoch in range(start_epoch, epochs_to_train_now):\n",
        "    if device.type == 'cuda':\n",
        "        print(f\"\\n--- GPU Usage (start of Epoch {epoch+1}) ---\")\n",
        "        !nvidia-smi\n",
        "        print(\"-------------------------------------------\\n\")\n",
        "\n",
        "    # --- Training Phase ---\n",
        "    model.train() # Set model to training mode\n",
        "    running_loss = 0.0\n",
        "    progress_bar_train = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs_to_train_now} [Train]\")\n",
        "\n",
        "    for images, labels in progress_bar_train:\n",
        "        images, labels = images.to(device), labels.to(device) # Move data to GPU\n",
        "\n",
        "        optimizer.zero_grad() # Zero gradients\n",
        "        outputs = model(images) # Forward pass\n",
        "        loss = criterion(outputs, labels) # Calculate loss\n",
        "        loss.backward() # Backward pass\n",
        "        optimizer.step() # Update weights\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        avg_loss = running_loss / (progress_bar_train.n + 1) # Calculate average loss\n",
        "\n",
        "        progress_bar_train.set_postfix(loss=avg_loss) # Display current loss on the right of the progress bar\n",
        "\n",
        "    avg_train_loss = running_loss / len(train_loader)\n",
        "    print(f\"Epoch [{epoch+1}/{epochs_to_train_now}] Training complete - Average Training Loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "    # --- Validation Phase ---\n",
        "    model.eval() # Set model to evaluation mode\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    progress_bar_val = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{epochs_to_train_now} [Validation]\")\n",
        "\n",
        "    with torch.no_grad(): # Disable gradient calculation\n",
        "        for images, labels in progress_bar_val:\n",
        "            images, labels = images.to(device), labels.to(device) # Move data to GPU\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            progress_bar_val.set_postfix(val_loss=val_loss / (progress_bar_val.n + 1), acc=(100 * correct / total))\n",
        "\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "    val_accuracy = 100 * correct / total\n",
        "    print(f\"Epoch [{epoch+1}/{epochs_to_train_now}] Validation complete - Average Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")\n",
        "\n",
        "    # --- Learning Rate Scheduler Update ---\n",
        "    scheduler.step(avg_val_loss) # Update learning rate based on validation loss\n",
        "\n",
        "    # --- Model Saving Logic (Checkpoint) ---\n",
        "    # 1. Save the current epoch's model to a file with version info\n",
        "    # Filename includes epoch, validation accuracy, and validation loss\n",
        "    current_epoch_model_filename = f\"food101_resnet50_epoch_{epoch+1}_acc_{val_accuracy:.2f}_loss_{avg_val_loss:.4f}.pth\"\n",
        "    current_epoch_model_filepath = os.path.join(drive_path, current_epoch_model_filename)\n",
        "    # Save full checkpoint state\n",
        "    torch.save({\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'scheduler_state_dict': scheduler.state_dict(),\n",
        "        'best_val_accuracy': best_val_accuracy,\n",
        "        'best_val_loss': best_val_loss,\n",
        "    }, current_epoch_model_filepath)\n",
        "    print(f\"Epoch {epoch+1} model snapshot saved to: {current_epoch_model_filepath}\")\n",
        "\n",
        "\n",
        "    # 2. Determine whether to save as the best model (overwrite fixed-name file)\n",
        "    if val_accuracy > best_val_accuracy:\n",
        "        best_val_accuracy = val_accuracy\n",
        "        # Save full checkpoint state for the \"best\" model too\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'scheduler_state_dict': scheduler.state_dict(),\n",
        "            'best_val_accuracy': best_val_accuracy,\n",
        "            'best_val_loss': avg_val_loss, # Update best_val_loss here as well\n",
        "        }, model_save_path) # Overwrite the main food101_resnet50.pth\n",
        "        best_model_ever_saved_path = model_save_path # Update the actual path of the best model\n",
        "        print(f\"Validation accuracy improved! Best model saved to: {model_save_path} (Accuracy: {best_val_accuracy:.2f}%)\")\n",
        "    else:\n",
        "        print(f\"Keeping existing best model (Accuracy: {best_val_accuracy:.2f}%)\")\n",
        "\n",
        "print(f\"Model training complete. Final best model state should be located at: {best_model_ever_saved_path if best_model_ever_saved_path else model_save_path}\")\n",
        "\n",
        "\n",
        "# --- 6. Define Prediction Function ---\n",
        "print(\"\\n--- 6. Define Prediction Function ---\")\n",
        "def predict_image(image_path, model, class_names, calorie_dict):\n",
        "    \"\"\"\n",
        "    Predicts the food category in an image and estimates calories.\n",
        "\n",
        "    Args:\n",
        "        image_path (str): Path to the image file.\n",
        "        model (torch.nn.Module): The trained PyTorch model.\n",
        "        class_names (list): List of food class names.\n",
        "        calorie_dict (dict): Dictionary mapping food names to calorie estimates.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (Predicted class name, Confidence percentage, Estimated calorie value)\n",
        "    \"\"\"\n",
        "    # Use the same standard transformations as validation/test sets for prediction, no random augmentation\n",
        "    transform_predict = transforms.Compose([\n",
        "        transforms.Resize((256)), # Typically resize larger first\n",
        "        transforms.CenterCrop((224, 224)), # Then center crop to model input size\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    try:\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Image file not found: {image_path}\")\n",
        "        return None, None, None\n",
        "    except Exception as e:\n",
        "        print(f\"Error: Could not open image file: {e}\")\n",
        "        return None, None, None\n",
        "\n",
        "    input_tensor = transform_predict(image).unsqueeze(0).to(device)\n",
        "\n",
        "    model.eval() # Set model to evaluation mode\n",
        "    with torch.no_grad(): # Disable gradient calculation\n",
        "        output = model(input_tensor)\n",
        "        probabilities = torch.nn.functional.softmax(output, dim=1) # Calculate class probabilities\n",
        "        _, pred = torch.max(output, 1) # Get index of the highest probability class\n",
        "        class_idx = pred.item()\n",
        "\n",
        "    class_name = class_names[class_idx]\n",
        "    # Get calories from the loaded calorie_dict\n",
        "    calories = calorie_dict.get(class_name, \"Unknown\") # Get calories, \"Unknown\" if not found\n",
        "    confidence = probabilities[0][class_idx].item() * 100 # Calculate confidence percentage\n",
        "\n",
        "    return class_name, confidence, calories\n",
        "\n",
        "print(\"Prediction function predict_image defined.\")\n",
        "\n",
        "\n",
        "# --- 7. Final Test Set Evaluation (in Colab Notebook) ---\n",
        "print(\"\\n--- 7. Final Test Set Evaluation ---\")\n",
        "\n",
        "# Load the best model (ensure it's the one that performed best on the validation set)\n",
        "if os.path.exists(model_save_path):\n",
        "    try:\n",
        "        # Load the full checkpoint\n",
        "        checkpoint = torch.load(model_save_path, map_location=device)\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        # Optionally, load optimizer and scheduler states if needed for future training/debugging\n",
        "        # optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        # if 'scheduler_state_dict' in checkpoint:\n",
        "        #     scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
        "        print(f\"Best model loaded: {model_save_path}, for final testing.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading best model {model_save_path}: {e}. Will use current in-memory model for testing.\")\n",
        "else:\n",
        "    print(f\"Best model not found: {model_save_path}. Please ensure the model was trained and saved successfully. Will use current in-memory model.\")\n",
        "\n",
        "model.eval() # Set to evaluation mode\n",
        "test_correct = 0\n",
        "test_total = 0\n",
        "test_loss = 0.0\n",
        "progress_bar_test = tqdm(test_loader, desc=f\"Final Test Set Evaluation\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in progress_bar_test:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        test_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        test_total += labels.size(0)\n",
        "        test_correct += (predicted == labels).sum().item()\n",
        "        progress_bar_test.set_postfix(test_loss=test_loss / (progress_bar_test.n + 1), test_acc=(100 * test_correct / test_total))\n",
        "\n",
        "avg_test_loss = test_loss / len(test_loader)\n",
        "test_accuracy = 100 * test_correct / test_total\n",
        "print(f\"\\nFinal Test Set Evaluation Results:\")\n",
        "print(f\"Average Test Loss: {avg_test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%\")\n",
        "print(\"Reminder: This test set is randomly split from all Food-101 images, results are not directly comparable to official benchmarks.\")\n",
        "\n",
        "\n",
        "# --- 8. Create Demo UI (using Gradio) ---\n",
        "print(\"\\n--- 8. Create Demo UI (using Gradio) ---\")\n",
        "\n",
        "# Randomly select a few images from test_dataset as examples\n",
        "# Note: test_dataset.subset.indices contains indices from the original full_food101_dataset\n",
        "#       test_dataset.subset.dataset.image_paths contains the original relative paths list\n",
        "num_examples = 5 # Number of examples to display\n",
        "example_paths = []\n",
        "if len(test_dataset) > 0:\n",
        "    # Randomly select indices\n",
        "    random_indices = random.sample(range(len(test_dataset)), min(num_examples, len(test_dataset)))\n",
        "    for idx in random_indices:\n",
        "        # Get the original index from test_dataset\n",
        "        original_idx = test_dataset.subset.indices[idx]\n",
        "        # Get the relative path from the original full_food101_dataset (e.g., \"apple_pie/12345\")\n",
        "        relative_path = test_dataset.subset.dataset.image_paths[original_idx]\n",
        "        # Construct the full image file path\n",
        "        full_image_path = os.path.join(image_root, relative_path + \".jpg\")\n",
        "        example_paths.append(full_image_path)\n",
        "else:\n",
        "    print(\"Warning: Test dataset is empty, cannot generate example image paths.\")\n",
        "\n",
        "\n",
        "# Wrap predict_image into a function required by Gradio interface\n",
        "def gradio_predict_wrapper(image_file):\n",
        "    if image_file is None:\n",
        "        return \"Please upload an image.\"\n",
        "\n",
        "    image_path = image_file.name\n",
        "\n",
        "    predicted_class, confidence, estimated_calories = predict_image(image_path, model, class_names, calorie_dict)\n",
        "\n",
        "    if predicted_class:\n",
        "        result_str = (\n",
        "            f\"Predicted Class: **{predicted_class}**\\n\"\n",
        "            f\"Confidence: {confidence:.2f}%\\n\"\n",
        "            f\"Estimated Calories: approx. **{estimated_calories}** kcal\"\n",
        "        )\n",
        "        return result_str\n",
        "    else:\n",
        "        return \"Prediction failed, please check the image file.\"\n",
        "\n",
        "# Set up Gradio interface\n",
        "iface = gr.Interface(\n",
        "    fn=gradio_predict_wrapper,\n",
        "    inputs=gr.File(type=\"filepath\", label=\"Upload Food Image\"),\n",
        "    outputs=gr.Markdown(\"\"),\n",
        "    title=\"Food-101 Food Recognition and Calorie Estimation Demo\",\n",
        "    description=\"Recognize your uploaded food images with an AI model and provide calorie estimation.\",\n",
        "    examples=example_paths, # Use dynamically generated test set image examples\n",
        "    allow_flagging=\"never\",\n",
        "    css=\"footer {visibility: hidden}\"\n",
        ")\n",
        "\n",
        "# Launch Gradio interface\n",
        "print(\"\\nLaunching Gradio interface...\")\n",
        "print(\"Please click on the Public URL or Local URL below to access:\")\n",
        "iface.launch(debug=True, share=True)\n",
        "\n",
        "print(\"\\nAll code execution complete.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "rm9CBeEvMiPh"
      }
    }
  ]
}